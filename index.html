<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="qaCMVSBA7RFpff7FOlao62nyrODi3nB504j_xwOT94g" />
  <style type="text/css">
  /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 400
  }
  heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px; /* 19 */
    font-weight: 600 /* 1000 */
  }
  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
  strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 25px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }
  </style>
  <link rel="shortcut icon" href="images/icon_2.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Yutong Wang</title>
  <meta name="Yutong Wang's Homepage" http-equiv="Content-Type" content="Yutong Wang's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('send', 'pageview');
    </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>
 
<body>
<table width="900" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Yutong Wang</pageheading><br>
  </p>

  <tr>
    <td width="30%" valign="top"><a href="images/YutongWang.jpg"><img src="images/YutongWang.png" width="100%" style="border-radius:15px"></a>
    </td>

    <td width="70%" valign="top" align="justify">
    <p>
        My name is Yutong Wang (王语童). I am a third year Ph.D. student in the Department of <a href="https://cde.nus.edu.sg/me/">Mechanical Engineering</a> at the <a href="https://nus.edu.sg/">National University of Singapore</a>, advised by Professor <a href="https://www.marmotlab.org/bio.html">Guillaume Sartoretti</a>. Currently, I am a visiting student in the <a href="https://www.ri.cmu.edu/">Robotics Institute</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, advised by Professor <a href="https://jiaoyangli.me/">Jiaoyang Li</a>. Previously, I received my Master's degree in Mechanical Engineering from the National University of Singapore and a B.Eng. in Electrical Engineering and Automation from <a href=" https://en.shu.edu.cn/#carousel-banner "> Shanghai University </a>.
    <p>
      My research interests encompass Multi-Agent Reinforcement Learning (MARL), Multi-Agent Path Finding (MAPF), and communication learning within the MARL framework. Currently, I am focusing on integrating search-based MAPF algorithms with MARL to address large-scale, complex MAPF problems and their variations. My goal is to devise fundamental algorithms that balance computational efficiency with solution quality, and to deploy them on physical robots. Such problems are commonly encountered in fields such as warehouse logistics, manufacturing, and search-and-rescue operations.  
    </p>
    <p align=center>
        | <a href="Yutong_Wang_CV.pdf">CV</a> |
        <a href="mailto:yutong_wang@u.nus.edu">Email</a> |
        <a href="https://scholar.google.com/citations?user=vabFK6wAAAAJ&hl=en">Google Scholar</a> |
        <a href="https://github.com/wyt2019suzhou">Github</a> | 
    </p>
    </td>
  </tr>
</table>
<hr/>


<!-- selected publications -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Selected Publications</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2303.00605">
    <video playsinline autoplay loop muted src="videos/SCRIMP_video_Compressed.mp4" poster="./images/loading-icon.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/abs/2303.00605" id="SCRIMP">
      <heading>SCRIMP: Scalable Communication for Reinforcement- and Imitation-Learning-Based Multi-Agent Pathfinding</heading></a><br>
      <b>Yutong Wang</b>, Bairan Xiang, Shinan Huang, Guillaume Sartoretti<br>
      International Conference on Intelligent Robots and Systems 2023 (IROS 2023), Accepted.<br>
      </p>

      <div class="paper" id="scrimp">
      <a href="javascript:toggleblock('scrimp_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/2303.00605.pdf">pdf</a> |
      <a href="https://github.com/marmotlab/SCRIMP">code</a> |
        
      <p align="justify"> <i id="scrimp_abs">Trading off performance guarantees in favor of scalability, the Multi-Agent Path Finding (MAPF) community has recently started to embrace Multi-Agent Reinforcement Learning (MARL), where agents learn to collaboratively generate individual, collision-free (but often suboptimal) paths. Scalability is usually achieved by assuming a local field of view (FOV) around the agents, helping scale to arbitrary world sizes. However, this assumption significantly limits the amount of information available to the agents, making it difficult for them to enact the type of joint maneuvers needed in denser MAPF tasks. In this paper, we propose SCRIMP, where agents learn individual policies from even very small (down to 3x3) FOVs, by relying on a highly-scalable global/local communication mechanism based on a modified transformer. We further equip agents with a state-value-based tie-breaking strategy to further improve performance in symmetric situations, and introduce intrinsic rewards to encourage exploration while mitigating the long-term credit assignment problem. Empirical evaluations on a set of experiments indicate that SCRIMP can achieve higher performance with improved scalability compared to other state-of-the-art learning-based MAPF planners with larger FOVs, and even yields similar performance as a classical centralized planner in many cases. Ablation studies further validate the effectiveness of our proposed techniques. Finally, we show that our trained model can be directly implemented on real robots for online MAPF through high-fidelity simulations in gazebo.</i></p>

      </div>
    </td>
  </tr>
  
  <tr>
    <td width="40%" valign="top" align="center"><a href="https://arxiv.org/abs/2201.11994">
    <video playsinline autoplay loop muted src="videos/sac.mp4" poster="./images/loading-icon.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a></td>
    <td width="60%" valign="top">
      <p><a href="https://arxiv.org/abs/2201.11994" id="FCMNET">
      <heading>FCMNet: Full Communication Memory Net for Team-Level Cooperation in Multi-Agent Systems</heading></a><br>
      <b>Yutong Wang</b>, Guillaume Sartoretti<br>
      International Conference on Autonomous Agents and Multiagent Systems 2022 (AAMAS 2022), Accepted.<br>
      </p>

      <div class="paper" id="fcmnet">
      <a href="javascript:toggleblock('fcmnet_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/2201.11994.pdf">pdf</a> |
      <a href="https://github.com/marmotlab/FCMNet">code</a> |

      <p align="justify"> <i id="fcmnet_abs">Decentralized cooperation in partially-observable multi-agent systems requires effective communications among agents. To support this effort, this work focuses on the class of problems where global communications are available but may be unreliable, thus precluding differentiable communication learning methods. We introduce FCMNet, a reinforcement learning based approach that allows agents to simultaneously learn a) an effective multi-hop communications protocol and b) a common, decentralized policy that enables team-level decision-making. Specifically, our proposed method utilizes the hidden states of multiple directional recurrent neural networks as communication messages among agents. Using a simple multi-hop topology, we endow each agent with the ability to receive information sequentially encoded by every other agent at each time step, leading to improved global cooperation. We demonstrate FCMNet on a challenging set of StarCraft II micromanagement tasks with shared rewards, as well as a collaborative multi-agent pathfinding task with individual rewards. There, our comparison results show that FCMNet outperforms state-of-the-art communication-based reinforcement learning methods in all StarCraft II micromanagement tasks, and value decomposition methods in certain tasks. We further investigate the robustness of FCMNet under realistic communication disturbances, such as random message loss or binarized messages (i.e., non-differentiable communication channels), to showcase FMCNet's potential applicability to robotic tasks under a variety of real-world conditions.</i></p>

      </div>
    </td>
  </tr>

  <tr>
    <td width="40%" valign="top" align="center"><a href="https://link.springer.com/article/10.1007/s43154-022-00091-8">
    <img src="images/methods.png" alt="sym" width="60%">
    </a></td>
    <td width="60%" valign="top">
      <p><a href="https://link.springer.com/article/10.1007/s43154-022-00091-8" id="Review">
      <heading>Distributed Reinforcement Learning for Robot Teams: a Review</heading></a><br>
      <b>Yutong Wang</b>, Mehul Damani, Pamela Wang, Yuhong Cao, Guillaume Sartoretti<br>
      Current Robotics Reports, Accepted.<br>
      </p>

      <div class="paper" id="review">
      <a href="javascript:toggleblock('review_abs')">abstract</a> |
      <a href="https://arxiv.org/pdf/2204.03516.pdf">pdf</a> |

      <p align="justify"> <i id="review_abs">This survey reports the challenges surrounding decentralized model-free MARL for multi-robot cooperation and existing classes of approaches. We present benchmarks and robotic applications along with a discussion on current open avenues for research.</i></p>

      </div>
    </td>
  </tr>


</table>
<div id="recent-news">
  <h2>Recent News</h2>
  <ul>
    <li>
      <span class="news-date">2024-1-29</span> - <span class="news-summary"> Our paper <a href="https://arxiv.org/abs/2310.08350">Alpha: Attention-based long-horizon pathfinding in highly-structured areas</a> was accepted to <a href="https://2024.ieee-icra.org/">ICRA 2024</a>.</span>
    </li>
    <li>
      <span class="news-date">2024-1-15</span> - <span class="news-summary"> I started my one-year visit at Carnegie Mellon University!</span>
    </li>
    <li>
      <span class="news-date">2023-10-1</span> - <span class="news-summary">I physically attended <a href="https://ieee-iros.org/">IROS 2023</a> in Detroit, USA.</span>
    </li>
    <li>
      <span class="news-date">2023-5-29</span> - <span class="news-summary">I physically attended <a href="https://aamas2023.soton.ac.uk/">AAMAS 2023</a> and <a href="https://www.icra2023.org/">ICRA 2023</a> in London, UK.</span>
    </li>
    <!-- Add more news items here -->
  </ul>
</div>


<script xml:space="preserve" language="JavaScript">

hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
  hideblock('review_abs');
</script>
<script xml:space="preserve" language="JavaScript">
    hideblock('scrimp_abs');
  </script>
<script xml:space="preserve" language="JavaScript">
    hideblock('fcmnet_abs');
  </script>
</body>


</html>
