<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="qaCMVSBA7RFpff7FOlao62nyrODi3nB504j_xwOT94g" />
  <style type="text/css">
  /* Design Credits: Jon Barron and Deepak Pathak and Abhishek Kar and Saurabh Gupta*/
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 400
  }
  heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px; /* 19 */
    font-weight: 600 /* 1000 */
  }
  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }
  strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 16px;
    font-weight: 600 /* 800 */
  }
  strongred {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    color: 'red' ;
    font-size: 16px
  }
  sectionheading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 15px;
    font-weight: 600
  }
  pageheading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 25px;
    font-weight: 400
  }
  .ImageBorder
  {
      border-width: 1px;
      border-color: Black;
  }
  </style>
  <link rel="shortcut icon" href="images/icon.png">
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Jingtian Yan</title>
  <meta name="Jingtian Yan's Homepage" http-equiv="Content-Type" content="Jingtian Yan's Homepage">
  <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
  <!-- Start : Google Analytics Code -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-XXXXX-Y', 'auto');
    ga('send', 'pageview');
    </script>
  <!-- End : Google Analytics Code -->
  <!-- Scramble Script by Jeff Donahue -->
  <script src="js/scramble.js"></script>
</head>
 
<body>
<table width="900" border="0" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr><td>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <p align="center">
    <pageheading>Jingtian Yan</pageheading><br>
  </p>

  <tr>
    <td width="30%" valign="top"><a href="images/JingtianYan.jpg"><img src="images/JingtianYan.png" width="100%" style="border-radius:15px"></a>
    </td>

    <td width="70%" valign="top" align="justify">
    <p>
        I am currently a research assistant in the Robotics Institute at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, supervised by Prof. <a href="https://jiaoyangli.me/">Jiaoyang Li</a>. My research interests include multi-robot coordination, autonomous exploration, and multi-agent motion planning.    </p>
    <p>
        Previously, I completed my MSc in Electrical and Computer Engineering at Carnegie Mellon University, co-advised by Prof. <a href="https://frc.ri.cmu.edu/~zhangji/">Ji Zhang</a> and Prof. <a href="https://www.ri.cmu.edu/ri-faculty/sebastian-scherer/">Sebastian Scherer</a>. I received my bachelor's degree in Automation from Zhejiang University.
    </p>
    <p align=center>
        | <a href="resources/JingtianYan_CV.pdf">CV</a> |
        <a href="mailto:jingtianyan@outlook.com">Email</a> |
        <a href="https://scholar.google.com/citations?user=JjaOG98AAAAJ&hl=en">Google Scholar</a> |
        <a href="https://github.com/JingtianYan/">Github</a> | 
    </p>
    </td>
  </tr>
</table>
<hr/>


<!-- selected publications -->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr><td><sectionheading>&nbsp;&nbsp;Selected Publications</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
  <tr>
    <td width="40%" valign="top" align="center"><a href="https://robot-parkour.github.io">
    <video playsinline autoplay loop muted src="videos/psb_demo.mp4" poster="./images/loading-icon.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a></td>
    <td width="60%" valign="top">
      <p><a href="https://jingtianyan.github.io" id="PARKOUR">
      <heading>Multi-Agent Motion Planning with Bézier Curve Optimization under Kinodynamic Constraints</heading></a><br>
      <b>Jingtian Yan</b>, Jiaoyang Li<br>
      IEEE Robotics and Automation Letters (RA-L), under review.<br>
      </p>

      <div class="paper" id="psb">
      <a href="https://arxiv.org/pdf/2311.14145.pdf">pdf</a> |
      <a href="javascript:toggleblock('psb_abs')">abstract</a> |
      <!-- <a shape="rect" href="javascript:togglebib('psb')" class="togglebib">bibtex</a> | -->
      <a href="https://arxiv.org/abs/2311.14145">arXiv</a> |
      <!-- <a href="https://github.com/ZiwenZhuang/parkour">code</a> | -->
      <!-- <a href="https://www.youtube.com/watch?v=M7lDCSF0KP0">video</a> -->

      <p align="justify"> <i id="psb_abs">Parkour is a grand challenge for legged locomotion that requires robots to overcome various obstacles rapidly in complex environments. Existing methods can generate either diverse but blind locomotion skills or vision-based but specialized skills by using reference animal data or complex rewards. However, autonomous parkour requires robots to learn generalizable skills that are both vision-based and diverse to perceive and react to various scenarios. In this work, we propose a system for learning a single end-to-end vision-based parkour policy of diverse parkour skills using a simple reward without any reference motion data. We develop a reinforcement learning method inspired by direct collocation to generate parkour skills, including climbing over high obstacles, leaping over large gaps, crawling beneath low barriers, squeezing through thin slits, and running. We distill these skills into a single vision-based parkour policy and transfer it to a quadrupedal robot using its egocentric depth camera. We demonstrate that our system can empower two different low-cost robots to autonomously select and execute appropriate parkour skills to traverse challenging real-world environments.</i></p>

<!-- <pre xml:space="preserve">
@inproceedings{zhuang2023robot,
  author = {Zhuang, Ziwen and Fu, Zipeng and 
          Wang, Jianren and Atkeson, Christopher and 
          Schwertfeger, Sören and Finn, Chelsea and
          Zhao, Hang},
  title = {Robot Parkour Learning},
  booktitle = {Conference on Robot Learning ({CoRL})},
  year = {2023}
}
</pre> -->
      </div>
    </td>
  </tr>
  
  <tr>
    <td width="40%" valign="top" align="center"><a href="https://ieeexplore.ieee.org/abstract/document/10138598">
    <video playsinline autoplay loop muted src="videos/mui-tare-demo.mp4" poster="images/mui-tare_cover.png" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a></td>
    <td width="60%" valign="top">
      <p><a href="https://ieeexplore.ieee.org/abstract/document/10138598" id="MUITARE">
      <heading>MUI-TARE: Cooperative Multi-Agent Exploration With Unknown Initial Position</heading></a><br>
      <b>Jingtian Yan</b>, Xingqiao Lin, Zhongqiang Ren, Shiqi Zhao, Jieqiong Yu, Chao Cao, Peng Yin, Ji Zhang, and Sebastian Scherer<br>
      IEEE Robotics and Automation Letters (RA-L), 2023.<br>
      </p>

      <div class="paper" id="muitare">
      <a href="https://arxiv.org/pdf/2209.10775.pdf">pdf</a> |
      <a href="javascript:toggleblock('muitare_abs')">abstract</a> |
      <!-- <a href="javascript:toggleblock('material_review_abs')">bibtex</a> | -->
      <a shape="rect" href="javascript:togglebib('muitare')" class="togglebib">bibtex</a> |
      <a href="https://arxiv.org/abs/2209.10775">arXiv</a> |
      <a href="https://www.youtube.com/watch?v=imSKHg3T1Wo">video</a>

      <p align="justify"> <i id="muitare_abs">Multi-agent exploration of a bounded 3D environment with the unknown initial poses of agents is a challenging problem. It requires both quickly exploring the environments and robustly merging the sub-maps built by the agents. Most existing exploration strategies directly merge two sub-maps built by different agents when a single frame observation is matched, which can lead to incorrect merging due to the false-positive detection of the overlap and is thus not robust. In the meanwhile, some recent place recognition methods use sequence matching for robust data association. However, naively applying these sequence matching methods to multi-agent exploration may require one agent to repeat a large amount of another agent's history trajectory so that a sequence of matched observation can be established, which reduces the overall exploration time efficiency. To intelligently balance the robustness of sub-map merging and exploration efficiency, we develop a new approach for lidar-based multi-agent exploration, which can direct one agent to repeat another agent's trajectory in an adaptive manner based on the quality indicator of the sub-map merging process. Additionally, our approach extends the recent single-agent hierarchical exploration strategy to multiple agents in a cooperative manner for agents whose sub-maps are merged, to improve exploration efficiency. Our experiments show that our approach is up to 50% more efficient than the baselines while merging sub-maps robustly.</i></p>
      <p align="justify"> <i id="material_review_abs">@ARTICLE{yan2023mui-tare,<br>
        author={Yan, Jingtian and Lin, Xingqiao and Ren, Zhongqiang and Zhao, Shiqi and Yu, Jieqiong and Cao, Chao and Yin, Peng and Zhang, Ji and Scherer, Sebastian},\n
        journal={IEEE Robotics and Automation Letters}, 
        title={MUI-TARE: Cooperative Multi-Agent Exploration With Unknown Initial Position}, 
        year={2023},
        volume={8},
        number={7},
        pages={4299-4306},
        doi={10.1109/LRA.2023.3281262}}</i></p>

<pre xml:space="preserve">
    @ARTICLE{yan2023mui-tare,<br>
        author={Yan, Jingtian and Lin, Xingqiao and Ren, Zhongqiang and Zhao, Shiqi and Yu, Jieqiong and Cao, Chao and Yin, Peng and Zhang, Ji and Scherer, Sebastian},\n
        journal={IEEE Robotics and Automation Letters}, 
        title={MUI-TARE: Cooperative Multi-Agent Exploration With Unknown Initial Position}, 
        year={2023},
        volume={8},
        number={7},
        pages={4299-4306},
        doi={10.1109/LRA.2023.3281262}}
</pre>
      </div>
    </td>
  </tr>

</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
    <tr><td><sectionheading>&nbsp;&nbsp;Projects</sectionheading></td></tr>
</table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
<tr>
    <td width="40%" valign="top" align="center"><a href="https://github.com/DockDockGo/ddg_multi_robot_planner">
    <video playsinline autoplay loop muted src="videos/demo_adg_v2.mp4" poster="./images/loading-icon.gif" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a></td>
    <td width="60%" valign="top">
    <p><a href="https://github.com/DockDockGo/ddg_multi_robot_planner" id="mfi">
    <heading>Multi-Agent Path Finding and Robust Execution in Warehouse</heading></a><br>
    <b>Jingtian Yan</b>, Jiaoyang Li<br>
    </p>

    <div class="paper" id="mfi">
    <a href="javascript:toggleblock('mfi_abs')">Background</a> |
    <a href="https://github.com/DockDockGo/ddg_multi_robot_planner">code</a> |
    <a href="">video</a>

    <p align="justify"> <i id="mfi_abs"></i></p>

    </div>
    </td>
</tr>

<tr>
    <td width="40%" valign="top" align="center"><a href="https://github.com/JingtianYan/autonomous_exploration_development_environment_isaac_sim">
    <video playsinline autoplay loop muted src="videos/issaac_TARE.mp4" poster="" alt="sym" width="90%" style="padding-top:0px;padding-bottom:0px;border-radius:15px;"></video>
    </a></td>
    <td width="60%" valign="top">
    <p><a href="https://github.com/JingtianYan/autonomous_exploration_development_environment_isaac_sim" id="MANIPLOCO">
    <heading>Autonomous Exploration Development Environment (Isaac Sim)</heading></a><br>
    <b>Jingtian Yan</b>, Ji Zhang<br>
    </p>

    <div class="paper" id="exploration_isaac_sim">
    <a href="javascript:toggleblock('exploration_isaac_sim_abs')">Background</a> |
    <a href="https://github.com/JingtianYan/autonomous_exploration_development_environment_isaac_sim">code</a> |
    <a href="https://www.youtube.com/watch?v=Kpt596Q3FoU">video</a>

    <p align="justify"> <i id="exploration_isaac_sim_abs">The project is designed for enhancing system development and robot deployment for ground-based autonomous navigation and exploration using the NVIDIA Isaac-sim. It encompasses autonomous navigation modules such as collision avoidance, terrain traversability analysis, waypoint following, and more, along with a suite of visualization tools. This project utilizes the hospital environment and Carter robot from the Isaac example files.</i></p>

    </div>
    </td>
</tr>

</table>

<hr/>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="2">
        <tr><td><br><p align="right">
        Website template from <a href="http://www.cs.berkeley.edu/~barron/">here</a> and <a href="http://www.cs.cmu.edu/~dpathak/">here</a>
        </font></p></td></tr>
    </table>

  </td></tr>
</table>

<script xml:space="preserve" language="JavaScript">

hideallbibs();
</script>
<script xml:space="preserve" language="JavaScript">
    hideblock('abs');
  </script>
<script xml:space="preserve" language="JavaScript">
  hideblock('material_review_abs');
</script>
<script xml:space="preserve" language="JavaScript">
    hideblock('psb_abs');
  </script>
<script xml:space="preserve" language="JavaScript">
    hideblock('muitare_abs');
  </script>
<script xml:space="preserve" language="JavaScript">
    hideblock('exploration_isaac_sim_abs');
  </script>
<script xml:space="preserve" language="JavaScript">
    hideblock('mfi_abs');
  </script>
</body>


</html>
