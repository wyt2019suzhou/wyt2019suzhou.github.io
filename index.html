<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jingtian Yan</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/cmu.png" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jingtian Yan
                </p>
                <p>I'm a research scientist at <a href="https://ai.google/research">Google Research</a> in San Francisco, where I lead a small team that mostly works on <a href="https://www.matthewtancik.com/nerf">NeRF</a>.
                </p>
                <p>
                  At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">VR</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://blog.google/products/maps/three-maps-updates-io-2022/">Maps</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I've received the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
				  <a href="https://www.threads.net/@jonbarron">Threads</a> &nbsp;/&nbsp;
				  <a href="https://bsky.app/profile/jonbarron.bsky.social">Bluesky</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jonbarron/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JingtianYan.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JingtianYan.png" class="hoverZoomLink"></a>
              </td>
            </tr>
 
<!-- publications -->

        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Selected Publications</h2>
                <p>
                  I'm interested in computer vision, machine learning, optimization, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
              </tr>
          
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="camp_stop()" onmouseover="camp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                <div class="two" id='camp_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/camp.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/camp.png' width="160">
                </div>
                <script type="text/javascript">
                function camp_start() {
                    document.getElementById('camp_image').style.opacity = "1";
                }

                function camp_stop() {
                    document.getElementById('camp_image').style.opacity = "0";
                }
                camp_stop()
                </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://camp-nerf.github.io/">
                <span class="papertitle">CamP: Camera Preconditioning for Neural Radiance Fields</span>
                </a>
                <br>
                <a href="https://keunhong.com/">Keunhong Park</a>,
                <a href="https://henzler.github.io/">Philipp Henzler</a>,
                <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                <strong>Jonathan T. Barron</strong>,
                <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>
                <br>
                <em>SIGGRAPH Asia</em>, 2023
                <br>
                <a href="https://camp-nerf.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2308.10902">arXiv</a>
                <p></p>
                <p>
                Preconditioning based on camera parameterization helps NeRF and camera extrinsics/intrinsics optimize better together.
                </p>
            </td>
            </tr>

            
            <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0">
                <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                    <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
                    <source src="images/psb.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                    </video>
                </div>
                    <img src='images/zipnerf.jpg' width="160">
                </div>
                <script type="text/javascript">
                    function zipnerf_start() {
                    document.getElementById('zipnerf_image').style.opacity = "1";
                    }

                    function zipnerf_stop() {
                    document.getElementById('zipnerf_image').style.opacity = "0";
                    }
                    zipnerf_stop()
                </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="http://jonbarron.info/zipnerf">
                    <span class="papertitle">Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields</span>
                </a>
                <br>
                <strong>Jonathan T. Barron</strong>,
                <a href="https://bmild.github.io/">Ben Mildenhall</a>,
                <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
                <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
                <a href="https://phogzone.com/">Peter Hedman</a>
                <br>
                <em>ICCV</em>, 2023 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Finalist)</strong></font>
                <br>
                <a href="http://jonbarron.info/zipnerf">project page</a>
                /
                <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
                /
                <a href="https://arxiv.org/abs/2304.06706">arXiv</a>
                <p></p>
                <p>
                Combining mip-NeRF 360 and grid-based models like Instant NGP lets us reduce error rates by 8%&ndash;77% and accelerate training by 24x.
                </p>
                </td>
            </tr>

<!-- Projects -->

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Projects</h2>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
            </tr>
        
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          
          <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='db3d_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="videos/issaac_TARE.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/project1.jpg' width="160">
              </div>
              <script type="text/javascript">
                  function db3d_start() {
                  document.getElementById('db3d_image').style.opacity = "1";
                  }

                  function db3d_stop() {
                  document.getElementById('db3d_image').style.opacity = "0";
                  }
                  db3d_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dreambooth3d.github.io/">
                  <span class="papertitle">autonomous_exploration_development_environment_isaac_sim</span>
              </a>
              <br>
              
      <a href="https://amitraj93.github.io/">Amit Raj</a>, <a href="https://www.linkedin.com/in/srinivas-kaza-64223b74">Srinivas Kaza</a>, <a href="https://poolio.github.io/">Ben Poole</a>, <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>, <a href="https://natanielruiz.github.io/">Nataniel Ruiz</a>, 
      <a href="https://bmild.github.io/">Ben Mildenhall</a>, <a href="https://scholar.google.com/citations?user=I2qheksAAAAJ">Shiran Zada</a>, <a href="https://kfiraberman.github.io/">Kfir Aberman</a>, <a href="http://people.csail.mit.edu/mrub/">Michael Rubinstein</a>, 
              <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li</a>, <a href="https://varunjampani.github.io/">Varun Jampani</a>
              <br>
              <em>ICCV</em>, 2023
              <br>
              <a href="https://dreambooth3d.github.io/">project page</a> / 
              <a href="https://arxiv.org/abs/2303.13508">arXiv</a>
              <p></p>
              <p>The repository is meant for leveraging system development and robot deployment for ground-based autonomous navigation and exploration on the NVIDIA Isaac-sim. Containing autonomous navigation modules such as collision avoidance, terrain traversability analysis, waypoint following, etc, and a set of visualization tools. This repository use the hospital environment and carter robot from the Isaac example files, see here for Isaac-sim environment installation and Nucleus server setup.</p>
              </td>
          </tr>

          

          <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                  <div class="two" id='bakedsdf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/bakedsdf_after.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/bakedsdf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                  function bakedsdf_start() {
                  document.getElementById('bakedsdf_image').style.opacity = "1";
                  }

                  function bakedsdf_stop() {
                  document.getElementById('bakedsdf_image').style.opacity = "0";
                  }
                  bakedsdf_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://bakedsdf.github.io/">
                  <span class="papertitle">BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis</span>
              </a>
              <br>
              <a href="https://lioryariv.github.io/">Lior Yariv*</a>,
              <a href="https://phogzone.com/">Peter Hedman*</a>,
              <a href="https://creiser.github.io/">Christian Reiser</a>,
              <a href="https://dorverbin.github.io/">Dor Verbin</a>,  <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://szeliski.org/RichardSzeliski.htm">Richard Szeliski</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>
              <br>
              <em>SIGGRAPH</em>, 2023
              <br>
              <a href="https://bakedsdf.github.io/">project page</a>
              /
              <a href="https://www.youtube.com/watch?v=fThKXZ6uDTk">video</a>
              /
              <a href="https://arxiv.org/abs/2302.14859">arXiv</a>
              <p></p>
              <p>
              We use SDFs to bake a NeRF-like model into a high quality mesh and do real-time view synthesis.
              </p>
              </td>
          </tr>
            
          
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
